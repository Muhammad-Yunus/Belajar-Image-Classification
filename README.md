# Belajar Image Classification

- Pertemuan 1 : **Basic Neural Network** [[View]](https://github.com/Muhammad-Yunus/Belajar-Image-Classification/tree/main/Pertemuan%201)
    - Intro to Neural Network (Basic Concept, Layer, Activation & Loss Function)
    - Train Simple Neural Network using Pytorch on MNIST Dataset
    - Model Evaluation (Accuracy, Precision, Recall & Confusion Matrix)<br><br>
- Pertemuan 2 : **Neural Network Optimization** [[View]](https://github.com/Muhammad-Yunus/Belajar-Image-Classification/tree/main/Pertemuan%202)
    - Experiment with Neural Network (Adding Layer & Change Activation)
    - Intro to Neural Network Optimizer
    - Experiment with Neural Network (Change Optimizer & Learning Rate Decay)
    - Intro to Dropout Layer & Training Overfitting 
    - Experiment Handling Overfitting using Dropout Layer<br><br>
- Pertemuan 3 : **Basic Convolution Neural Network (CNN)** [[View]](https://github.com/Muhammad-Yunus/Belajar-Image-Classification/tree/main/Pertemuan%203)
    - Intro to Convolution Neural Network
    - Train Simple CNN using Pytorch on MNIST Dataset
    - Experiment Adding Dropout Layer to CNN
    - Intro to Batch Normalization Layer
    - Experiment Adding Batch Normalization Layer to CNN<br><br>
- Pertemuan 4 : **CNN with Attention Mechanism** [[View]](https://github.com/Muhammad-Yunus/Belajar-Image-Classification/tree/main/Pertemuan%204)
    - Intro to Attention Mechanism
    - Train Simple CNN with Attention using Pytorch on MNIST Dataset
    - Intro to Channel based Attention : Squeeze and Excitation layers
    - Implement Simple CNN with Squeeze and Excitation layers in Pytorch<br><br>
- Pertemuan 5 : **Intro to CNN based Image Classification Model**
    - Intro CNN Image Classification Model (Resnet, VGG, EfficientNet)
    - Intro to TorchHub
    - Inference EfficientNet with or Without Channel Attention Squeeze and Excitation<br><br>
- Pertemuan 6 : **Transfer Learning on CNN based Image Classification Model**
    - Intro Image Classification Dataset
    - Transfer Learning EfficientNet using Torchvision with or Without Channel Attention Squeeze and Excitation

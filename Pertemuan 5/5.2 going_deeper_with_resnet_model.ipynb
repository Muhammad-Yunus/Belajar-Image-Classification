{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Going deeper with ResNet Model\n",
    "\n",
    "⚠️⚠️⚠️ *Please open this notebook in Google Colab* by click below link ⚠️⚠️⚠️<br><br>\n",
    "<a href=\"https://colab.research.google.com/github/Muhammad-Yunus/Belajar-Image-Classification/blob/main/Pertemuan%205/5.2%20going_deeper_with_resnet_model.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><br><br><br>\n",
    "- Click `Connect` button in top right Google Colab notebook,<br>\n",
    "<img src=\"resource/cl-connect-gpu.png\" width=\"250px\">\n",
    "- If connecting process completed, it will turn to something look like this<br>\n",
    "<img src=\"resource/cl-connect-gpu-success.png\" width=\"250px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check GPU connected into Colab environment is active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Deeper Network vs Model Performance\n",
    "- In the past experiment, we are able to achieve a good enough performance for image classification by just simply stacking several layer into the network, <br>\n",
    "<img src=\"resource/small-net.png\" width=\"100%\"> <br>\n",
    "- What if we keep adding extra layer and making the network got bigger and bigger?\n",
    "    - Deeper convolutional neural networks some times beneficial to give a model ability to learn better.\n",
    "- Until the train and validation accuracy is <font color=\"orange\">saturated (won't changed)</font>, or even worst.<br>\n",
    "<img src=\"resource/deep-network.png\" width=\"100%\"><br>\n",
    "- This problem related to the network <font color=\"orange\">degradation</font>.\n",
    "    - Adding extra layer has no bennefit and accuracy remain the same.\n",
    "    - The network experiencing <font color=\"orange\">vanishing/exploding gradients</font>, making it hard to <font color=\"orange\">converge</font> by optimizer. <br>\n",
    "    <img src=\"resource/vanish-exploding-grad.png\" width=\"500px\"><br>\n",
    "- This is explain why stacking more layers in deep neural network, not always making model learn better.\n",
    "- When adding extra layer on that kind of situation, will just <font color=\"orange\">learn to do nothing</font> and the result is <font color=\"orange\">unchanged</font>.\n",
    "    - The layer now act like an <font color=\"orange\">Identity Function</font>, <br>\n",
    "    <img src=\"resource/Identity-Function.png\" width=\"550px\"><br>\n",
    "- On above illustration, we can verify that <font color=\"orange\">with or without the additional layer</font>, the result is <font color=\"orange\">unchanged</font>, so it makes sense if we just <font color=\"orange\">skip it</font> (a.k.a <font color=\"cyan\">Skip Connection</font>).    \n",
    "    - This ensures the network <font color=\"orange\">won’t degrade</font>.\n",
    "- <font color=\"cyan\">Skip Connection</font> allow the input to <font color=\"orange\">skip</font> a layer and get <font color=\"orange\">added</font> to the output of the next layer. \n",
    "    - This effectively means the network learns both the <font color=\"orange\">transformation</font> and an <font color=\"orange\">identity mapping</font>.<br>\n",
    "    <img src=\"resource/residual-block-cat.png\" width=\"600px\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Residual Block\n",
    "- Based on above idea Kaiming He et al in his paper *['Deep Residual Learning for Image Recognition' - arxiv.org](https://arxiv.org/abs/1512.03385)*, proposing <font color=\"orange\">Residual Block</font> to handling degradation problem in a very deep neural network. <br>\n",
    "<img src=\"resource/residual-block.png\" width=\"500px\"><br><i>regular block (left) vs Residual Block (right) - source [[link](https://d2l.ai/chapter_convolutional-modern/resnet.html)]</i><br><br>\n",
    "- It's called <font color=\"orange\">\"residual\"</font> because it represents the difference between the <font color=\"orange\">original signal</font> (input : $x$) and the <font color=\"orange\">modified signal</font> (output : $F(x)$).\n",
    "    - In the context of neural networks, a residual image captures what <font color=\"orange\">remains after subtracting</font> the modified from the original signal ($G(x)$). \n",
    "    - It’s like a <font color=\"orange\">visual residue</font> of the changes made. \n",
    "    - This concept helps models focus on learning changes or details that improve performance, rather than relearning everything from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementation of <font color=\"orange\">Residual Block</font> in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define <font color=\"orange\">Residual Block</font> following this structure, <br>\n",
    "<img src=\"resource/residual-block-2.png\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # Define first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        # Define first batch normalization layer\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        # Define second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        # Define second batch normalization layer\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first convolution -> batch normalization -> ReLU activation\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # Apply second convolution -> batch normalization\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # Add the input to the output\n",
    "        out += self.shortcut(x)\n",
    "        # Apply final ReLU activation\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess an image\n",
    "image = cv2.imread(\"cat.jpg\")  # Load image 'cat.jpg' using OpenCV\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "image = cv2.resize(image, (128, 128))\n",
    "\n",
    "# Convert image to tensor\n",
    "image = image.transpose((2, 0, 1))  # Change the order of dimensions from (H, W, C) to (C, H, W)\n",
    "input_image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a residual block and process the image\n",
    "residual_block = ResidualBlock(in_channels=3, out_channels=3)\n",
    "residual_image = residual_block(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residual (absolute difference between input and output)\n",
    "visual_residual = torch.abs(input_image - residual_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensors to NumPy arrays for visualization\n",
    "input_image_np = input_image.squeeze().permute(1, 2, 0).detach().numpy().astype(np.uint8)\n",
    "residual_image_np = residual_image.squeeze().permute(1, 2, 0).detach().numpy().astype(np.uint8)\n",
    "visual_residual_np = visual_residual.squeeze().permute(1, 2, 0).detach().numpy().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the images\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(input_image_np)\n",
    "ax[0].set_title('Input Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(residual_image_np)\n",
    "ax[1].set_title('Output Image (After Residual Block)')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(visual_residual_np)\n",
    "ax[2].set_title('Visual Residual')\n",
    "ax[2].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resource/Resnet-18-Model.png\" width=\"900px\"><br><i>ResNet18 - source [[link](https://d2l.ai/chapter_convolutional-modern/resnet.html)]</i><br><br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3c6a0b3",
      "metadata": {
        "id": "d3c6a0b3"
      },
      "source": [
        "## 5.3 Resnet Pretrained Model - Pytorch Hub\n",
        "\n",
        "⚠️⚠️⚠️ *Please open this notebook in Google Colab* by click below link ⚠️⚠️⚠️<br><br>\n",
        "<a href=\"https://colab.research.google.com/github/Muhammad-Yunus/Belajar-Image-Classification/blob/main/Pertemuan%205/5.3%20pytorch_hub_resnet.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><br><br><br>\n",
        "- Click `Connect` button in top right Google Colab notebook,<br>\n",
        "<img src=\"resource/cl-connect-gpu.png\" width=\"250px\">\n",
        "- If connecting process completed, it will turn to something look like this<br>\n",
        "<img src=\"resource/cl-connect-gpu-success.png\" width=\"250px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41730573",
      "metadata": {},
      "source": [
        "- Check GPU connected into Colab environment is active"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "797f1c04",
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9432652e",
      "metadata": {},
      "source": [
        "<br><br><br><br>\n",
        "#### 5.3.1 Intro Pytorch Hub\n",
        "<img src=\"resource/PyTorch_logo.png\" width=\"300px\" style=\"background-color:white; padding:10px; border-radius:8px\"><br>\n",
        "- <font color=\"orange\">Discover</font> and <font color=\"orange\">publish models</font> to a pre-trained model repository designed for research exploration.\n",
        "- Open Pytorch Hub in browser [https://pytorch.org/hub/](https://pytorch.org/hub/)<br>\n",
        "<img src=\"resource/torch-hub.png\" width=\"900px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e8135b4",
      "metadata": {},
      "source": [
        "<br><br><br><br>\n",
        "#### 5.3.2 ResNet Pretrained Model in Pytorch Hub\n",
        "- <font color=\"orange\">ResNet</font> - Deep residual networks pre-trained on ImageNet\n",
        "    - Open in browser [https://pytorch.org/hub/pytorch_vision_resnet/](https://pytorch.org/hub/pytorch_vision_resnet/)\n",
        "<img src=\"resource/torch-hub-resnet.png\" width=\"900px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4286cda",
      "metadata": {},
      "source": [
        "- Load ResNet model from Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ad304b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "# or any of these variants\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36b223f6",
      "metadata": {},
      "source": [
        "- Download sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efb3b2d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d4ed345",
      "metadata": {},
      "source": [
        "- All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least `224`. \n",
        "- The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]` and `std = [0.229, 0.224, 0.225]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9992faf0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cc5418b",
      "metadata": {},
      "source": [
        "- move the input and model to GPU for speed if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c41d526",
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0885d6dd",
      "metadata": {},
      "source": [
        "- Predict the input tensor `dog.jpg`\n",
        "    - Output tensor of shape 1000, with confidence scores over ImageNet's 1000 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36f0a2d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "\n",
        "print(output[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74a1cb12",
      "metadata": {},
      "source": [
        "- The output has un-normalized scores. \n",
        "    - To get probabilities, you can run a <font color=\"orange\">softmax</font> on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "745264df",
      "metadata": {},
      "outputs": [],
      "source": [
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "print(probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "527f567a",
      "metadata": {},
      "source": [
        "- Download ImageNet labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3210ea6",
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceb1fe1d",
      "metadata": {},
      "source": [
        "- Read the categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c8ac96f",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a040cdd6",
      "metadata": {},
      "source": [
        "- Show top categories per image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2411337",
      "metadata": {},
      "outputs": [],
      "source": [
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b36fba4f",
      "metadata": {
        "id": "b36fba4f"
      },
      "source": [
        "### Model Description\n",
        "\n",
        "Resnet models were proposed in \"Deep Residual Learning for Image Recognition\".\n",
        "Here we have the 5 versions of resnet models, which contains 18, 34, 50, 101, 152 layers respectively.\n",
        "Detailed model architectures can be found in Table 1.\n",
        "Their 1-crop error rates on ImageNet dataset with pretrained models are listed below.\n",
        "\n",
        "| Model structure | Top-1 error | Top-5 error |\n",
        "| --------------- | ----------- | ----------- |\n",
        "|  resnet18       | 30.24       | 10.92       |\n",
        "|  resnet34       | 26.70       | 8.58        |\n",
        "|  resnet50       | 23.85       | 7.13        |\n",
        "|  resnet101      | 22.63       | 6.44        |\n",
        "|  resnet152      | 21.69       | 5.94        |\n",
        "\n",
        "### References\n",
        "\n",
        " - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
        " - [Original Notebook from Pytorch Team](https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/pytorch_vision_resnet.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

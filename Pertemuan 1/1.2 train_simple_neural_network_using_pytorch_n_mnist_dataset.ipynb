{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Train Simple Neural Network using Pytorch on MNIST Dataset\n",
    "- About MNIST Dataset\n",
    "- Load and Split Dataset Split\n",
    "- Label Encoding\n",
    "- Create Simple Neural Network Model\n",
    "- Run Training Model\n",
    "- Visualize Training Loss vs Trining Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 About MNIST Dataset\n",
    "- We will use the **MNIST dataset**, a collection of **60,000** labeled handwritten digits dataset in 10 classes.<br>\n",
    "- Handwritten digits in the MNIST dataset are <i><font color='orange'>28x28 pixel</font></i> grayscale images. \n",
    "- The neural network we will build <i><font color='orange'>classifies the handwritten digits</font></i> in their **10 classes** (0, .., 9).\n",
    "<img src=\"resource/MNIST.png\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file dataset\\train already exists.\n",
      "A subdirectory or file dataset\\test already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir dataset\\train\n",
    "!mkdir dataset\\test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "\n",
    "# Define data transformations (optional, but recommended)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download the MNIST dataset\n",
    "train_set = datasets.MNIST(root='MNIST', train=True, transform=transform, download=True)\n",
    "test_set = datasets.MNIST(root='MNIST', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER = 'dataset\\\\train'\n",
    "TEST_FOLDER = 'dataset\\\\test'\n",
    "\n",
    "# Access individual samples\n",
    "for idx, (image, label) in enumerate(train_set):\n",
    "    name = f\"{TRAIN_FOLDER}\\\\train_{idx}\"\n",
    "    image_pil = transforms.ToPILImage()(image)\n",
    "    image_pil.save(f\"{name}.png\")\n",
    "    with open(f\"{name}.txt\", 'w') as label_file:\n",
    "        label_file.write(str(label))\n",
    "\n",
    "# Repeat the same process for the test set\n",
    "for idx, (image, label) in enumerate(test_set):\n",
    "    name = f\"{TEST_FOLDER}\\\\test_{idx}\"\n",
    "    image_pil = transforms.ToPILImage()(image)\n",
    "    image_pil.save(f\"{name}.png\")\n",
    "    with open(f\"{name}.txt\", 'w') as label_file:\n",
    "        label_file.write(str(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Load & Split Dataset \n",
    "- Load each image on MNIST dataset using OpenCV\n",
    "- <i><font color='orange'>Convert to gray</font></i>, to make sure we only have single channel of 28x28 pixel data on each image\n",
    "- The simplest approach for classifying them is to use the <i><font color='orange'>28x28=784 pixels</font></i> as inputs for a 1-layer neural network.\n",
    "- That why we will convert the <i><font color='orange'>2D matrix of 28x28 pixel</font></i> into flatten <i><font color='orange'>1D array 784 pixel</font></i>.<br>\n",
    "<img src=\"resource/MNIST_Load.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Neural Network learned through a training process which requires a <i><font color='orange'>\"training dataset\"</font></i>. \n",
    "- We <i><font color='cyan'>need another dataset, never seen during training</font></i>, to evaluate the \"real-world\" performance of the network. It is called an <i><font color='orange'>\"validation dataset\"</font></i>.\n",
    "- Here we split the 60.000 labeled images MNIST dataset into <i><font color='orange'>60.000 data</font></i> for <i><font color='orange'>\"training dataset\"</font></i> and <i><font color='orange'>10.000 data</font></i> for <i><font color='orange'>\"validation dataset\"</font></i> <br>\n",
    "<img src=\"resource/MNIST_split.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Label Encoding\n",
    "- Label Encoding help model to map label as <i><font color='orange'>numerical representation</font></i> with ordering.\n",
    "- Model might learn some <i><font color='orange'>natural ordering between the different class labels</font></i> based on the labels. \n",
    "- Assigning them <i><font color='orange'>numbers in a scale</font></i> would implicitly create ordering and relations between different classes.\n",
    "- For this purpose, we will use <i><font color='orange'>One-hot Encoding</font></i> to encode label of MNIST dataset into look like this,<br>\n",
    "<img src=\"resource/MNIS_OneHot.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code apply one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Create Simple Neural Network Model\n",
    "- We will creating a simple Neural Network model, with only Input and Output Layer\n",
    "- The <i><font color='cyan'>Input Layer</font></i> will have <i><font color='orange'>784</font></i> neuron (*same size with flattened 28x28=784 pixels on each MNIST dataset*)\n",
    "- The <i><font color='cyan'>Output Layer</font></i> will have <i><font color='orange'>10 neuron</font></i> (*same size with a number of dataset class*)<br>\n",
    "<img src=\"resource/NN_SingleDense.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each \"neuron\" in a neural network does a <i><font color='cyan'>weighted sum of all of its inputs</font></i>, adds a constant called the <i><font color='cyan'>\"bias\"</font></i>.\n",
    "<img src=\"resource/NN_03.png\" width=\"400px\"><br><br>\n",
    "- On above network will have <i><font color='cyan'>784x10 weight</font></i>.<br>\n",
    "<img src=\"resource/NN_WeightedSum.gif\" width=\"600px\"><br><br>\n",
    "- Then feeds the result through some non-linear <i><font color='cyan'>\"activation function\"</font></i>. <br>\n",
    "- We will use <i><font color='cyan'>Softmax</font></i> for that purpose.<br>\n",
    "<img src=\"resource/NN_08.png\" height=\"175px\"><img src=\"resource/NN_07.gif\" height=\"175px\"><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for neural network model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=784, out_features=128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=128, out_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=64, out_features=10),  # 10 classes (digits 0-9)\n",
    "    nn.LogSoftmax(dim=1)  # Log probabilities for classification\n",
    ").to('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then to <i><font color='cyan'>measure how good</font></i> the trained model, we will measure distance between what the <i><font color='cyan'>network tells us</font></i> and the <i><font color='cyan'>correct answers</font></i>.\n",
    "- For classification problems we will use <i><font color='cyan'>\"cross-entropy distance\"</font></i> (a.k.a loss function).\n",
    "<img src=\"resource/NN_LOSS.png\" width=\"600px\"><br><br>\n",
    "- <i><font color='cyan'>\"Training\"</font></i> model actually means using training images and labels to <i><font color='cyan'>adjust weights</font></i> and <i><font color='cyan'>biases</font></i> so as to <i><font color='cyan'>minimise</font></i> the <i><font color='cyan'>cross-entropy</font></i> loss function.\n",
    "- That process is called <i><font color='cyan'>Optimizer</font></i>. We will talk more about this in <i><font color='cyan'>Pertemuan 2</font></i>, but keep in mind we will use <i><font color='orange'>SGD Optimizer</font></i> for now.<br><br>\n",
    "- We are also able to add metric to measure like model accuracy, precission, recall, or etc.\n",
    "- For now we just use <i><font color='orange'>accuracy metric</font></i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code setup optimizer, loss function & metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 Run Training Model\n",
    "- To run training process, we can use the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0708\n",
      "Epoch 2/10, Loss: 0.0123\n",
      "Epoch 3/10, Loss: 0.0032\n",
      "Epoch 4/10, Loss: 0.0013\n",
      "Epoch 5/10, Loss: 0.0018\n",
      "Epoch 6/10, Loss: 0.0054\n",
      "Epoch 7/10, Loss: 0.0026\n",
      "Epoch 8/10, Loss: 0.0155\n",
      "Epoch 9/10, Loss: 0.0248\n",
      "Epoch 10/10, Loss: 0.0631\n"
     ]
    }
   ],
   "source": [
    "# code run training\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):  # You can adjust the number of epochs\n",
    "    for images, labels in trainLoader:\n",
    "        images, labels = images.to('cpu'), labels.to('cpu')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images.view(-1, 784))\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{10}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 Visualize Loss vs Accuracy\n",
    "- We are also able to visualize Loss vs Accuracy using the following code,\n",
    "- <i><font color='orange'>Loss will decrease</font></i> as the <i><font color='orange'>epoch increases</font></i>, whereas <i><font color='orange'>accuracy will increase</font></i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.31%\n"
     ]
    }
   ],
   "source": [
    "# code visualize Loss & Accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in testLoader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = net(images.view(-1, 784))\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "# Source \n",
    "- https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist#2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

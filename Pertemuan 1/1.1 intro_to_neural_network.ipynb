{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Basic Neural Network - Intro to Neural Network\n",
    "- Neural Network Concept\n",
    "- Neural Network Layer\n",
    "- Activation Function\n",
    "- Loss Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Neural Network Concept\n",
    "\n",
    "- Neural networks are algorithms that can be used to perform **nonlinear** statistical modeling. [1](https://pubmed.ncbi.nlm.nih.gov/8892489/)\n",
    "- Ability to implicitly detect **complex nonlinear** relationships between **dependent** and **independent** variables. [1](https://pubmed.ncbi.nlm.nih.gov/8892489/)\n",
    "- Ability to detect all possible interactions between **predictor variables**. [1](https://pubmed.ncbi.nlm.nih.gov/8892489/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understanding how Neural Network work using **Tensorflow Playground** [[Open in Browser]](https://playground.tensorflow.org/#activation=linear&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.24959&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
    "<iframe src=\"https://playground.tensorflow.org/#activation=linear&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.24959&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\" width=\"100%\" height=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Neural Network Layer\n",
    "\n",
    "- Based on above ilustration we can observe that **Neural Network** in **classification**,\n",
    "    - Has several **Layer** (Input Layer, Hidden Layer, Output Layer)\n",
    "    - **Input Layer** Dimension / Size is related to Number of Feature\n",
    "    - **Fature** is individual measurable value within a data in dataset\n",
    "        - Like a pixel value in image dataset\n",
    "        - width & height in Iris Species dataset, etc.\n",
    "    - **Hidden Layer** is used to transform input to a new representation.\n",
    "        - Can be something like reduced dimention of data\n",
    "        - Can be identifing more pattern based on supplied feature (edge, shape, etc.)\n",
    "    - **Output Layer** is used to perform classification using Hidden Layer output\n",
    "        - Dimension / Size is equal to number of dataset class\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's take a look into highlighted **Node**<br>\n",
    "<img src=\"resource/NN_02.png\" width=\"400px\"><br><br>\n",
    "- Basic formulation <br>\n",
    "<img src=\"resource/NN_03.png\" width=\"400px\">\n",
    "- Where,\n",
    "    - $x_1$ and $x_2$ is input layer with two feature\n",
    "    - $z_1$ is calculated result in hidden layer\n",
    "    - $w_1$ is weight between $x_1$ and $z_1$\n",
    "    - $w_2$ is weight between $x_2$ and $z_2$\n",
    "    - $b$ is bias, it's used to adjust the result value lower or upper.\n",
    "- Then we can simply find $z_1$ as, <br>\n",
    "    $z_1$ = $x_1*w_1 + x_2*w_2 + b$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Activation Function\n",
    "- $z_1$ result is not final, the value must be applied into **Activation Function**\n",
    "- Activation Function can **adjust sensitivity** of the output value and to introduce the **non-linearity** to the model\n",
    "- By adding non-linearity to the model, naturaly helping model to **learn** and **better represent complex patterns**.<br>\n",
    "<img src=\"resource/NN_04.png\" width=\"600px\"><br><br>\n",
    "- **Relu Activation Function**\n",
    "    - Most used in hidden layer<br>\n",
    "    <img src=\"resource/NN_05.png\" width=\"350px\"><br><br>\n",
    "- **Sigmoid Activation Function**<br>\n",
    "    - Traditional activation function, can be used in hidden or output layer<br>\n",
    "    <img src=\"resource/NN_06.png\" width=\"350px\"><br><br>\n",
    "- **Sigmoid Activation Function**<br>\n",
    "    - Most used in output layer, has significat effet to increase the largest value, making it dominating the prediction result. \n",
    "    <img src=\"resource/NN_08.png\" height=\"175px\"><img src=\"resource/NN_07.gif\" height=\"175px\"><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Loss Function\n",
    "\n",
    "- When neural network produces predictions from input data, we need to measure **how good they**.\n",
    "- i.e. the distance between what the **network tells us / prediction result** and the **correct answers**, often called **\"labels\"**\n",
    "- For classification problems to measure how close the **prediction result** to the **correct label** is using **\"cross-entropy distance\"**\n",
    "- We will call this our error or \"loss\" function<br>\n",
    "<img src=\"resource/NN_09.png\" width=\"700px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Txw5R4oeQ_y"
      },
      "source": [
        "## 6.1 Transfer Learning ResNet-34 using Custom Dataset\n",
        "- Prepare Dataset\n",
        "- Run Transfer Learning ResNet-34\n",
        "- Evaluate Model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW8oKTGHeQ_0"
      },
      "source": [
        "‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è *Please open this notebook in Google Colab* by click below link ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è<br><br>\n",
        "<a href=\"https://colab.research.google.com/github/Muhammad-Yunus/Belajar-Image-Classification/blob/main/Pertemuan%206/6.1%20transfer_learning_resnet_34.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><br><br><br>\n",
        "- Click `Connect` button in top right Google Colab notebook,<br>\n",
        "<img src=\"https://github.com/Muhammad-Yunus/Belajar-Image-Classification/blob/main/Pertemuan%206/resource/cl-connect-gpu.png?raw=1\" width=\"250px\">\n",
        "- If connecting process completed, it will turn to something look like this<br>\n",
        "<img src=\"https://github.com/Muhammad-Yunus/Belajar-Image-Classification/blob/main/Pertemuan%206/resource/cl-connect-gpu-success.png?raw=1\" width=\"250px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5i7qweXeQ_1"
      },
      "source": [
        "- Check GPU connected into Colab environment is active"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP07y-o9eQ_2",
        "outputId": "260fa04c-c70d-40b3-e3dc-4be720a88dd3"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2L6vl1weQ_3"
      },
      "source": [
        "<br><br><br><br><br>\n",
        "#### 6.1.1 Transfer Learning ResNet-34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "2IYREzYceQ_3"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import gdown\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "# clear output cell\n",
        "display.clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "0U1St9wGeQ_4"
      },
      "outputs": [],
      "source": [
        "DATASET_NAME = 'apple2orange' # the dataset name\n",
        "DATASET_LABELS = [\"apple\", \"orange\"] # define dataset labels\n",
        "DATASET_NUM_CLASS = len(DATASET_LABELS) # number of class in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "svT3apEHeQ_4"
      },
      "outputs": [],
      "source": [
        "# default using gdrive_id Dataset `apple2orange_dataset.zip` (1rHN19c2DmqPKcTNyxjbENIePMVONXAYI)\n",
        "gdrive_id = '1rHN19c2DmqPKcTNyxjbENIePMVONXAYI' # <-----  ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è USE YOUR OWN GDrive ID FOR CUSTOM DATASET ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n",
        "\n",
        "# download zip from GDrive\n",
        "url = f'https://drive.google.com/uc?id={gdrive_id}'\n",
        "gdown.download(url, DATASET_NAME + \".zip\", quiet=False)\n",
        "\n",
        "# unzip dataset\n",
        "!unzip {DATASET_NAME}.zip -d {DATASET_NAME}\n",
        "\n",
        "# clear output cell\n",
        "display.clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "oeX3vUGSeQ_4"
      },
      "outputs": [],
      "source": [
        "# Define Custom Dataset class\n",
        "# it's just helper to load image dataset using OpenCV and convert to pytorch tensor\n",
        "# also doing a label encoding using one-hot encoding\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.image_files = sorted([file for file in os.listdir(root_dir) if file.lower().endswith('.png') or file.lower().endswith('.jpg')])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Read image from corresponding .png file\n",
        "        image_path = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = cv2.imread(image_path)  # Load image using OpenCV\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "        image = cv2.resize(image, (224,224)) # resize input image to comply ResNet18 input dimension 3x224x224\n",
        "        image = torch.from_numpy(image).to(torch.float32)  # Convert NumPy array to PyTorch tensor\n",
        "        image = image.permute(2, 0, 1)  # Change the order of dimensions from (H, W, C) to (C, H, W)\n",
        "        image = image / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "        # Read label from corresponding .txt file\n",
        "        label_path = os.path.splitext(image_path)[0] + \".txt\"\n",
        "        with open(label_path, 'r') as label_file:\n",
        "            label = label_file.read().strip()  # read label from .txt\n",
        "\n",
        "        # Apply one-hot encoding into label\n",
        "        labels_tensor = torch.tensor(DATASET_LABELS.index(label))\n",
        "        one_hot_encoded = F.one_hot(labels_tensor, num_classes=DATASET_NUM_CLASS).to(torch.float32)\n",
        "\n",
        "        return image, one_hot_encoded\n",
        "\n",
        "# instantiate dataset\n",
        "# in here the image dataset is not loaded yet\n",
        "# we only read all image files names in fataset folder\n",
        "all_train_dataset = CustomDataset(root_dir=f'{DATASET_NAME}/dataset/train')\n",
        "test_dataset = CustomDataset(root_dir=f'{DATASET_NAME}/dataset/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsCQZiuJeQ_5",
        "outputId": "e8534cf4-7ab5-4a44-9762-27928f96cb1f"
      },
      "outputs": [],
      "source": [
        "print(f\"All Train Dataset : {len(all_train_dataset)} data\")\n",
        "print(f\"Test Dataset : {len(test_dataset)} data\")\n",
        "\n",
        "num_all_train = len(all_train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwSIa4zzeQ_5",
        "outputId": "ff8676b5-a40d-420f-aa51-9bfb1b4604bc"
      },
      "outputs": [],
      "source": [
        "# Split 'all_train_dataset' into 'train' and 'validation' set using `random_split()` function\n",
        "\n",
        "num_train = int( num_all_train* 0.75)\n",
        "num_val = num_all_train - num_train\n",
        "train_dataset, validation_dataset = random_split(all_train_dataset, [num_train, num_val])\n",
        "\n",
        "print(f\"Train Dataset : {len(train_dataset)} data\")\n",
        "print(f\"Validation Dataset : {len(validation_dataset)} data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "oU3ck1yTeQ_5"
      },
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zivv46Ncj3n3"
      },
      "source": [
        "#### ‚ùÑÔ∏è‚ùÑÔ∏è‚ùÑÔ∏è Pretrained Model Freezein Transfer Learning ‚ùÑÔ∏è‚ùÑÔ∏è‚ùÑÔ∏è\n",
        "- In transfer learning, when using a pre-trained model like ResNet for image classification, <font color=\"orange\">freezing</font> all layers except the last fully connected layer is a common practice for the following reasons:\n",
        "\n",
        "  1. <font color=\"orange\">Preserve Learned Features</font> :\n",
        "      - ResNet and similar models are pre-trained on large datasets like ImageNet, which contains millions of labeled images.\n",
        "      - Through this training, the model learns general features (like edges, textures, shapes) in the early and middle layers, which are applicable across a wide variety of tasks.\n",
        "      - These features are useful even for your custom dataset, so you want to preserve them instead of retraining those layers from scratch.\n",
        "  2. <font color=\"orange\">Avoid Overfitting</font> :\n",
        "      - When you fine-tune a model on a smaller, domain-specific dataset, if you retrain the entire network, it might overfit to your smaller dataset.\n",
        "      - Freezing the majority of the layers helps prevent this by keeping the pre-learned, general features intact and only adjusting the last layer to make the model specific to your classification task.\n",
        "  3. <font color=\"orange\">Reduce Training Time</font> :\n",
        "      - Training all layers in a deep model like ResNet from scratch is computationally expensive and time-consuming.\n",
        "      - By freezing most layers, you significantly reduce the training time because the gradients do not need to be computed for the frozen layers.<br><br><br>\n",
        "\n",
        "      <img src=\"resource/Freeze-Resnet-18-Architecture.png\" width=\"95%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "yd6WvPUleQ_6"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained ResNet-34 model from torch.hub\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
        "\n",
        "\n",
        "# ‚ùÑÔ∏è‚ùÑÔ∏è‚ùÑÔ∏è Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the final fully connected layer, adjust the output to match dimension with size DATASET_NUM_CLASS \n",
        "model.fc = nn.Linear(model.fc.in_features, DATASET_NUM_CLASS)\n",
        "\n",
        "# Ensure only the last layer's parameters are trainable\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# setup optimizer, loss function & metric\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_function = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWXYl4feeQ_6"
      },
      "source": [
        "- To run training process, we can use the following code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maDOTGO2eQ_6",
        "outputId": "30df1cac-f5e0-4743-9e29-43307758a660"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPlYMPEDeQ_7",
        "outputId": "7a4b10fc-a891-4f5b-c7e7-43cae1c5345d"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer, loss_function):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    # Add progress bar for training loop\n",
        "    progress_bar = tqdm(train_loader, desc='Training', leave=False)\n",
        "\n",
        "    for inputs, labels in progress_bar:\n",
        "        inputs = inputs.to(device) # move inputs to device\n",
        "        labels = labels.to(device) # move labels to device\n",
        "\n",
        "        # resets the gradients of all the model's parameters before the backward pass\n",
        "        optimizer.zero_grad()\n",
        "        # pass 3D BATCH_SIZEx3x224x224 input tensor to CNN model\n",
        "        outputs = model(inputs)\n",
        "        # calc loss value\n",
        "        loss = loss_function(outputs, labels)\n",
        "        # computes the gradient of the loss with respect to each parameter in model\n",
        "        loss.backward()\n",
        "        # adjust model parameter\n",
        "        optimizer.step()\n",
        "        # sum loss value\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate correct & total prediction\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels.argmax(1)).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "        # Update progress bar description with current loss\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Calculate average training loss\n",
        "    average_train_loss = running_loss / len(train_loader.dataset)\n",
        "    # Calculate training accuracy\n",
        "    train_accuracy = correct_predictions / total_predictions\n",
        "    return average_train_loss, train_accuracy\n",
        "\n",
        "def validate(model, val_loader, loss_function):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    # Add progress bar for validation loop\n",
        "    progress_bar = tqdm(val_loader, desc='Validating', leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in progress_bar:\n",
        "            inputs = inputs.to(device) # move inputs to device\n",
        "            labels = labels.to(device) # move labels to device\n",
        "\n",
        "            # pass 2D 3x224x224 input tensor to CNN model\n",
        "            outputs = model(inputs)\n",
        "            # calc loss value\n",
        "            loss = loss_function(outputs, labels)\n",
        "            # sum loss value\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate correct & total prediction\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_predictions += (predicted == labels.argmax(1)).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "            # Update progress bar description with loss\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Calculate average validation loss\n",
        "    average_val_loss = running_loss / len(val_loader.dataset)\n",
        "    # Calculate validation accuracy\n",
        "    val_accuracy = correct_predictions / total_predictions\n",
        "    return average_val_loss, val_accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# This is a training loop for selected Epoch\n",
        "# each epoch will process all training and validation set, chunked into small batch size data\n",
        "# then measure the loss & accuracy of training and validation set\n",
        "NUM_EPOCH = 50      # you can change this value\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(NUM_EPOCH):\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCH}\")\n",
        "\n",
        "    train_loss, train_accuracy = train(model, train_loader, optimizer, loss_function)\n",
        "    val_loss, val_accuracy = validate(model, validation_loader, loss_function)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_accuracy * 100)  # convert to percentage\n",
        "    val_accuracies.append(val_accuracy * 100)  # convert to percentage\n",
        "\n",
        "    print(f\"Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Train Accuracy = {train_accuracy:.4f}, Val Accuracy = {val_accuracy:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmR8HxCDeQ_7"
      },
      "source": [
        "- Plot Loss and Accuracy of Training vs Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "tDBlRkF2eQ_7",
        "outputId": "3e4f9d13-95db-4ccd-f8a2-a08c3719bb51"
      },
      "outputs": [],
      "source": [
        "# visualize Loss & Accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = list(range(1, NUM_EPOCH + 1))\n",
        "\n",
        "# Plotting loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_losses, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_losses, 'r', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plotting accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_accuracies, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracies, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptk3_MWTeQ_7"
      },
      "source": [
        "- Evaluate Model, find Precision, Recal each class data, measure accuracy and compute confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc4ZxV54eQ_7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# define evaluate function for test set\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    # Add progress bar for validation loop\n",
        "    progress_bar = tqdm(test_loader, desc='Evaluating', leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # iterate over all batched test set\n",
        "        for inputs, labels in progress_bar:\n",
        "            inputs = inputs.to(device) # move inputs to device\n",
        "            labels = labels.to(device) # move labels to device\n",
        "\n",
        "            # pass 2D 3x224x224 input tensor to CNN model\n",
        "            outputs = model(inputs)\n",
        "            # get prediction\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            # collect all labels & preds\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    return all_labels, all_preds\n",
        "\n",
        "# Evaluation on test set\n",
        "all_labels, all_preds = evaluate(model, test_loader)\n",
        "all_labels = np.argmax(all_labels, axis=1)\n",
        "\n",
        "# Calculate classification report\n",
        "labels = [str(i) for i in range(DATASET_NUM_CLASS)]\n",
        "print(classification_report(all_labels, all_preds, target_names=labels))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('Actual Class')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih3q1iHVeQ_7"
      },
      "source": [
        "- Download Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSprUnyqeQ_8"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'trained_resnet34_model.pt')\n",
        "\n",
        "# Download the model file\n",
        "from google.colab import files\n",
        "files.download('trained_resnet34_model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br><br><br><br>\n",
        "#### üß™üß™üß™ Experiment Result ResNet-18 with 50 epoch\n",
        "- Dataset : Apple2Orange\n",
        "    - Train : 1510 images\n",
        "    - Validation : 504 images\n",
        "    - Test : 514 images\n",
        "    - Number of class : 2\n",
        "- Train vs Validation Accuracy & Loss<br>\n",
        "<img src=\"resource/Resnet-18-50epoch-apple2orange.png\" width=\"900px\"><br><br>\n",
        "- Classification Report<br>\n",
        "<img src=\"resource/Resnet-18-50epoch-apple2orange-report.png\" width=\"500px\">\n",
        "- Confusion Matrix<br>\n",
        "<img src=\"resource/Resnet-18-50epoch-apple2orange-eval.png\" width=\"500px\">"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
